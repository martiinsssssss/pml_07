{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CNN RL AGENT VISUALISATION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook containing the code to generate videos of the agent playing the game once trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import wandb\n",
    "import datetime\n",
    "import torch\n",
    "import torch.nn as nn        \n",
    "import torch.optim as optim \n",
    "from torchsummary import summary\n",
    "import collections\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from IPython.display import HTML\n",
    "from tqdm import tqdm\n",
    "import ale_py\n",
    "from gymnasium.wrappers import MaxAndSkipObservation, ResizeObservation, GrayscaleObservation, FrameStackObservation, ReshapeObservation\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.10.1+6a7e0ae)\n",
      "[Powered by Stella]\n"
     ]
    }
   ],
   "source": [
    "gym.register_envs(ale_py)\n",
    "ENV_NAME = \"ALE/BeamRider-v5\"\n",
    "#ENV_NAME = \"ALE/Breakout-v5\"\n",
    "\n",
    "env = gym.make(ENV_NAME, render_mode = \"rgb_array\").unwrapped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrappers and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Action Space: Discrete(9)\n",
      "Modified Action Space: Discrete(8)\n",
      "MaxAndSkipObservation: (210, 160, 3)\n",
      "ResizeObservation    : (84, 84, 3)\n",
      "GrayscaleObservation : (84, 84, 1)\n",
      "ImageToPyTorch       : (1, 84, 84)\n",
      "ReshapeObservation   : (84, 84)\n",
      "FrameStackObservation: (4, 84, 84)\n",
      "ScaledFloatFrame     : (4, 84, 84)\n"
     ]
    }
   ],
   "source": [
    "class ImageToPyTorch(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        old_shape = self.observation_space.shape\n",
    "        self.observation_space = gym.spaces.Box(low=0.0, high=1.0, shape=(old_shape[-1], old_shape[0], old_shape[1]), dtype=np.float32)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        return np.moveaxis(observation, 2, 0)\n",
    "\n",
    "class ScaledFloatFrame(gym.ObservationWrapper):\n",
    "    def observation(self, obs):\n",
    "        return np.array(obs).astype(np.float32) / 255.0\n",
    "\n",
    "class RemoveNoOpWrapper(gym.ActionWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        # Remove the noop action by modifying the action space\n",
    "        assert isinstance(env.action_space, gym.spaces.Discrete), \"Action space must be Discrete\"\n",
    "        self.original_action_space = env.action_space\n",
    "        self.action_space = gym.spaces.Discrete(env.action_space.n - 1)  # Exclude noop\n",
    "\n",
    "    def action(self, action):\n",
    "        # Remap action index (e.g., 0 -> 1, 1 -> 2, etc.)\n",
    "        return action + 1\n",
    "\n",
    "    def reverse_action(self, action):\n",
    "        # Reverse remapping (if needed)\n",
    "        return action - 1\n",
    "\n",
    "def make_env(env_name, render_mode=None):\n",
    "    env = gym.make(env_name, render_mode=render_mode)\n",
    "    print(\"Original Action Space: {}\".format(env.action_space))\n",
    "    \n",
    "    if env_name == \"BeamRiderNoFrameskip-v4\":\n",
    "        # Remove Noop Action\n",
    "        env = RemoveNoOpWrapper(env)\n",
    "        print(f\"Modified Action Space: {env.action_space}\")\n",
    "\n",
    "    env = MaxAndSkipObservation(env, skip=4)\n",
    "    print(\"MaxAndSkipObservation: {}\".format(env.observation_space.shape))\n",
    "    #env = FireResetEnv(env)\n",
    "    env = ResizeObservation(env, (84, 84))\n",
    "    print(\"ResizeObservation    : {}\".format(env.observation_space.shape))\n",
    "    env = GrayscaleObservation(env, keep_dim=True)\n",
    "    print(\"GrayscaleObservation : {}\".format(env.observation_space.shape))\n",
    "    env = ImageToPyTorch(env)\n",
    "    print(\"ImageToPyTorch       : {}\".format(env.observation_space.shape))\n",
    "    env = ReshapeObservation(env, (84, 84))\n",
    "    print(\"ReshapeObservation   : {}\".format(env.observation_space.shape))\n",
    "    env = FrameStackObservation(env, stack_size=4)\n",
    "    print(\"FrameStackObservation: {}\".format(env.observation_space.shape))\n",
    "    env = ScaledFloatFrame(env)\n",
    "    print(\"ScaledFloatFrame     : {}\".format(env.observation_space.shape))\n",
    "    \n",
    "    return env\n",
    "\n",
    "env = make_env(ENV_NAME, render_mode = \"rgb_array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Env.        : (210, 160, 3)\n",
      "Original Action Space: Discrete(9)\n",
      "Modified Action Space: Discrete(8)\n",
      "MaxAndSkipObservation: (210, 160, 3)\n",
      "ResizeObservation    : (84, 84, 3)\n",
      "ImageToPyTorch       : (3, 84, 84)\n",
      "FrameStackObservation: (4, 3, 84, 84)\n",
      "ScaledFloatFrame     : (4, 3, 84, 84)\n"
     ]
    }
   ],
   "source": [
    "# RGB Adaptation using the BeamRiderNoFrameskip-v4 environment made with ChatGPTs help\n",
    "\n",
    "\"\"\"\n",
    "ENV_NAME = \"BeamRiderNoFrameskip-v4\"\n",
    "\n",
    "class ImageToPyTorch(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        old_shape = self.observation_space.shape\n",
    "        self.observation_space = gym.spaces.Box(low=0.0, high=1.0, shape=(old_shape[-1], old_shape[0], old_shape[1]), dtype=np.float32)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        return np.moveaxis(observation, 2, 0)\n",
    "\n",
    "class ScaledFloatFrame(gym.ObservationWrapper):\n",
    "    def observation(self, obs):\n",
    "        return np.array(obs).astype(np.float32) / 255.0\n",
    "\n",
    "class RemoveNoOpWrapper(gym.ActionWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        # Remove the noop action by modifying the action space\n",
    "        assert isinstance(env.action_space, gym.spaces.Discrete), \"Action space must be Discrete\"\n",
    "        self.original_action_space = env.action_space\n",
    "        self.action_space = gym.spaces.Discrete(env.action_space.n - 1)  # Exclude noop\n",
    "\n",
    "    def action(self, action):\n",
    "        # Remap action index (e.g., 0 -> 1, 1 -> 2, etc.)\n",
    "        return action + 1\n",
    "\n",
    "    def reverse_action(self, action):\n",
    "        # Reverse remapping (if needed)\n",
    "        return action - 1\n",
    "\n",
    "def make_env(env_name, render_mode=None):\n",
    "    #Creates a customized environment for training an RL agent. Maintains RGB observations without converting to grayscale.\n",
    "    env = gym.make(env_name, render_mode=render_mode)\n",
    "    print(\"Standard Env.        : {}\".format(env.observation_space.shape))\n",
    "    print(\"Original Action Space: {}\".format(env.action_space))\n",
    "    \n",
    "    # Remove Noop Action\n",
    "    env = RemoveNoOpWrapper(env)\n",
    "    print(f\"Modified Action Space: {env.action_space}\")\n",
    "\n",
    "    env = MaxAndSkipObservation(env, skip=4)  # Adjust skip frame as necessary\n",
    "    print(\"MaxAndSkipObservation: {}\".format(env.observation_space.shape))\n",
    "    env = ResizeObservation(env, (84, 84))  # Resize to a standard size\n",
    "    print(\"ResizeObservation    : {}\".format(env.observation_space.shape))\n",
    "    # Skip GrayscaleObservation to keep RGB colors\n",
    "    env = ImageToPyTorch(env)  # Change image channel ordering for PyTorch\n",
    "    print(\"ImageToPyTorch       : {}\".format(env.observation_space.shape))\n",
    "    env = FrameStackObservation(env, stack_size=4)  # Stack frames for temporal information\n",
    "    print(\"FrameStackObservation: {}\".format(env.observation_space.shape))\n",
    "    env = ScaledFloatFrame(env)  # Normalize pixel values\n",
    "    print(\"ScaledFloatFrame     : {}\".format(env.observation_space.shape))\n",
    "    return env\n",
    "\n",
    "env = make_env(ENV_NAME, render_mode = \"rgb_array\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN RL Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same implementation as in the training notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation based on Pol Vierge's of the M3-3_Activity_1 and the Example_1 (REINFORCE baseline on CartPole)\n",
    "class RLAgent:\n",
    "    # Initialize the agent\n",
    "    def __init__(self, env, lr = 0.003, gamma = 0.99, max_trjectories = 1000, horizon = 500, device = 'cpu'):\n",
    "        self.env = env\n",
    "        self.model = self.build_model().to(device)\n",
    "        self.lr = lr\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        self.gamma = gamma\n",
    "        self.max_trjectories = max_trjectories\n",
    "        self.horizon = horizon\n",
    "\n",
    "\n",
    "    # Build the model\n",
    "    def build_model(self):\n",
    "        input_shape = self.env.observation_space.shape[0]  \n",
    "        output_shape = self.env.action_space.n\n",
    "\n",
    "        net = nn.Sequential(\n",
    "            nn.Conv2d(input_shape, 32, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*7*7, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, output_shape)\n",
    "        )\n",
    "        return net\n",
    "    \n",
    "    # Perform a step in the environment\n",
    "    def step(self, transitions, current_state, render = False):\n",
    "        \n",
    "        state_ = torch.tensor(np.array([current_state], copy=False)).to(device) \n",
    "        # action selection using the model \n",
    "        actions_prob = self.model(state_)[0]\n",
    "        # sample action from the distribution\n",
    "        action = torch.distributions.Categorical(logits=actions_prob).sample().item()\n",
    "        \n",
    "        # if we want to get the image of the environment\n",
    "        if render:\n",
    "            img = self.env.render()\n",
    "\n",
    "        # take a step in the environment\n",
    "        previous_state = current_state\n",
    "        current_state, reward, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "       \n",
    "       # store the transition\n",
    "        transitions.append((previous_state, action, reward))\n",
    "\n",
    "        if render: \n",
    "            return current_state, done, transitions, img\n",
    "        else:\n",
    "            return current_state, done, transitions\n",
    "        \n",
    "\n",
    "    # Episode training\n",
    "    def train_episode(self, score, losses, t, horizon, verbose = True):\n",
    "        # reset the environment and get the initial state\n",
    "        current_state, _ = self.env.reset()\n",
    "\n",
    "        transitions = []\n",
    "        done = False\n",
    "\n",
    "        # run the episode until termination or horizon is reached\n",
    "        for _ in range(horizon):\n",
    "            current_state, done, transitions = self.step(transitions, current_state)\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        # calculate the returns\n",
    "        rewards = np.array([r for (s, a, r) in transitions])\n",
    "        score.append(np.sum(rewards))\n",
    "\n",
    "        batch_Gvals = []\n",
    "        R = 0\n",
    "        for r in reversed(rewards):\n",
    "            # compute the discounted return\n",
    "            R = r + self.gamma * R\n",
    "            batch_Gvals.insert(0, R)\n",
    "        batch_Gvals = torch.tensor(batch_Gvals, dtype=torch.float32, device=device)\n",
    "        \n",
    "        if len(batch_Gvals) > 1:\n",
    "            # standardize the returns\n",
    "            batch_Gvals = nn.functional.normalize(batch_Gvals, dim=0).to(device)\n",
    "\n",
    "        # Prepare the batches for the model\n",
    "        state_batch = torch.Tensor(np.array([s for (s, a, r) in transitions])).to(device)\n",
    "        action_batch = torch.LongTensor(np.array([a for (s, a, r) in transitions])).to(device)\n",
    "\n",
    "        # Predict action probabilities using the model\n",
    "        predicted_batch = self.model(state_batch)  # Probability distribution of actions\n",
    "        prob_batch = predicted_batch.gather(dim=1, index=action_batch.long().view(-1,1)).squeeze()\n",
    "        \n",
    "        # Loss calculation using the standardized returns (baseline)\n",
    "        loss = -torch.sum(torch.log(prob_batch) * (batch_Gvals))\n",
    "\n",
    "        # Optimize the model\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # get loss\n",
    "        loss = loss.item()\n",
    "        losses.append(loss)\n",
    "\n",
    "        if verbose:\n",
    "            if t % 100 == 0 and t > 0:\n",
    "                print(f'Trajectory {t}\\tAverage Score: {np.mean(score[-100:-1]):.2f}')\n",
    "\n",
    "        self.env.close()\n",
    "\n",
    "        return score, losses\n",
    "        \n",
    "    # Training function\n",
    "    def train(self, verbose = True):\n",
    "        score = []\n",
    "        losses = []\n",
    "        for t in tqdm(range(self.max_trjectories)):\n",
    "            score, losses = self.train_episode(score, losses, t, self.horizon, verbose = verbose)\n",
    "\n",
    "        self.plot_loss(losses)\n",
    "\n",
    "        # save model \n",
    "        torch.save(self.model.state_dict(), f'rlmodel_{self.lr}_{self.max_trjectories}_{self.horizon}.pth')\n",
    "        return score\n",
    "    \n",
    "    # function to test the agent\n",
    "    def watch_agent(self, model_path = None, T = 500, episodes = 100, device = 'cpu'):\n",
    "        \n",
    "        # load the model if a path is provided\n",
    "        if model_path:\n",
    "            self.model.load_state_dict(torch.load(model_path, weights_only=True, map_location=device))\n",
    "            self.model.eval()\n",
    "\n",
    "        # store the scores and images of the episodes to make a gif\n",
    "        score = []\n",
    "        ep_imgs = []\n",
    "\n",
    "        # run n episodes, store the images and the scores\n",
    "        for _ in tqdm(range(episodes)):\n",
    "            current_state, _ = self.env.reset()\n",
    "            images = []\n",
    "            transitions = []\n",
    "            for _ in range(T):\n",
    "                current_state, done, transitions, img = self.step(transitions, current_state, render = True)\n",
    "                images.append(Image.fromarray(img))\n",
    "                if done:\n",
    "                    break           \n",
    "            rewards = np.array([r for (s, a, r) in transitions])\n",
    "            score.append(np.sum(rewards))\n",
    "            ep_imgs.append(images)\n",
    "\n",
    "        video_name = 'video.gif'\n",
    "        # save a gif of the best episode to visualize the agent\n",
    "        if video_name in os.listdir():\n",
    "            video_name = f'video_{self.max_trjectories}_{self.horizon}_{datetime.datetime.now()}.gif'\n",
    "        \n",
    "        ep_imgs[np.argmax(np.array(score))][0].save(f\"videos/{video_name}\", save_all=True, append_images=images[1:], duration=60, loop=0)\n",
    "        \n",
    "        # plot the scores\n",
    "        self.visualise(score, show_avg= False, train=False, name = 'reward_plot')\n",
    "\n",
    "        # close Env\n",
    "        self.env.close()\n",
    "        \n",
    "    # visualisation function\n",
    "    def visualise(self, score, show_avg=True, train=True, name = 'reward_plot', folder = 'rewards'):\n",
    "        score = np.array(score)\n",
    "\n",
    "        plt.figure(figsize=(15, 7))\n",
    "        plt.ylabel(\"Trajectory duration\", fontsize=12)\n",
    "        plt.xlabel(\"Training iterations\", fontsize=12)\n",
    "        \n",
    "        # Plot the score\n",
    "        plt.plot(score, color='gray', linewidth=1, label='Score')\n",
    "        \n",
    "        # Plot the moving average if enabled\n",
    "        if show_avg:\n",
    "            N = 100  # Window size\n",
    "            avg_score = np.convolve(score, np.ones(N) / N, mode='valid')\n",
    "            plt.plot(avg_score, color='blue', linewidth=3, label='Moving Average (window=50)')\n",
    "        \n",
    "        # Scatter plot for individual points\n",
    "        plt.scatter(np.arange(score.shape[0]), score, color='green', linewidth=0.3)\n",
    "        \n",
    "        # Add a legend\n",
    "        plt.legend(fontsize=12)\n",
    "        \n",
    "        if train:\n",
    "            if f'{name}_{self.lr}_{self.max_trjectories}_{self.horizon}.png' in os.listdir(folder):\n",
    "                plt.savefig(f'{folder}/{name}_{self.lr}_{self.max_trjectories}_{self.horizon}_{datetime.datetime.now()}.png')\n",
    "            else:\n",
    "                plt.savefig(f'{folder}/{name}_{self.lr}_{self.max_trjectories}_{self.horizon}.png')\n",
    "        \n",
    "        else:\n",
    "            name = f'test_{name}'\n",
    "            if f'{name}.png' in os.listdir(folder):\n",
    "                plt.savefig(f'{folder}/{name}_{datetime.datetime.now()}.png')\n",
    "            else:\n",
    "                plt.savefig(f'{folder}/{name}.png')\n",
    "    \n",
    "    def plot_loss(self, losses):\n",
    "        plt.figure(figsize=(15, 7))\n",
    "        plt.ylabel(\"Loss\", fontsize=12)\n",
    "        plt.xlabel(\"Training iterations\", fontsize=12)\n",
    "        plt.plot(losses, color='gray', linewidth=1, label='Loss')\n",
    "        # save the plot\n",
    "        if f'loss_plot_skip4_{self.lr}_{self.max_trjectories}_{self.horizon}.png' in os.listdir():\n",
    "            plt.savefig(f'loss_plot_skip4_{self.lr}_{self.max_trjectories}_{self.horizon}_{datetime.datetime.now()}.png')\n",
    "        else:\n",
    "            plt.savefig(f'loss_plot_skip4_{self.lr}_{self.max_trjectories}_{self.horizon}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation based on Pol Vierge's of the M3-3_Activity_1 and the Example_1 (REINFORCE baseline on CartPole)\n",
    "# RGB Adaptation made with the help of ChatGPT 4o.\n",
    "\n",
    "\"\"\"\n",
    "class RLAgent:\n",
    "    # Initialize the agent\n",
    "    def __init__(self, env, lr = 0.003, gamma = 0.99, max_trjectories = 1000, horizon = 500, device = 'cpu'):\n",
    "        self.env = env\n",
    "        self.model = self.build_model().to(device)\n",
    "        self.lr = lr\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        self.gamma = gamma\n",
    "        self.max_trjectories = max_trjectories\n",
    "        self.horizon = horizon\n",
    "    \n",
    "    # Build the model\n",
    "    def build_model(self):\n",
    "        # Update input_shape for RGB channels\n",
    "        input_channels = self.env.observation_space.shape[1]  # This should be 3 for RGB\n",
    "        output_shape = self.env.action_space.n\n",
    "\n",
    "        net = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 32, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 7 * 7, 512),  # Ensure this matches the flattened size\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, output_shape)\n",
    "        )\n",
    "        return net\n",
    "    \n",
    "    # Perform a step in the environment\n",
    "    def step(self, transitions, current_state, render = False):\n",
    "        \n",
    "        \n",
    "        state_ = torch.tensor(np.array(current_state, copy=False)).to(device) \n",
    "\n",
    "        # action selection using the model \n",
    "        actions_prob = self.model(state_)[0]\n",
    "\n",
    "        # sample action from the distribution\n",
    "        action = torch.distributions.Categorical(logits=actions_prob).sample().item()\n",
    "        \n",
    "        # if we want to get the image of the environment\n",
    "        if render:\n",
    "            img = self.env.render()\n",
    "\n",
    "        # take a step in the environment\n",
    "        previous_state = current_state\n",
    "        current_state, reward, terminated, truncated, info = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        # store the transition\n",
    "        transitions.append((previous_state, action, reward))\n",
    "\n",
    "        if render: \n",
    "            return current_state, done, transitions, img\n",
    "        else:\n",
    "            return current_state, done, transitions\n",
    "        \n",
    "\n",
    "    # Episode training\n",
    "    def train_episode(self, score, losses, t, horizon, verbose = True):\n",
    "        # reset the environment and get the initial state\n",
    "        current_state, _ = self.env.reset()\n",
    "\n",
    "        transitions = []\n",
    "        done = False\n",
    "\n",
    "        # run the episode until termination or horizon is reached\n",
    "        for _ in range(horizon):\n",
    "            current_state, done, transitions = self.step(transitions, current_state)\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        # calculate the returns\n",
    "        rewards = np.array([r for (s, a, r) in transitions])\n",
    "        score.append(np.sum(rewards))\n",
    "\n",
    "        batch_Gvals = []\n",
    "        R = 0\n",
    "        for r in reversed(rewards):\n",
    "            # compute the discounted return\n",
    "            R = r + self.gamma * R\n",
    "            batch_Gvals.insert(0, R)\n",
    "        batch_Gvals = torch.tensor(batch_Gvals, dtype=torch.float32, device=device)\n",
    "        \n",
    "        # compute the standardized average return as a baseline: (x_i - mean) / std\n",
    "        if len(batch_Gvals) > 1:\n",
    "            batch_Gvals = nn.functional.normalize(batch_Gvals, dim=0).to(device)\n",
    "\n",
    "\n",
    "        # Prepare the batches for the model\n",
    "        state_batch = torch.tensor(np.array([s for (s, a, r) in transitions]), dtype=torch.float32)\n",
    "        state_batch = state_batch.permute(0, 2, 1, 3, 4).reshape(-1, 3, 84, 84).to(device)\n",
    "        action_batch = torch.LongTensor(np.array([a for (s, a, r) in transitions])).to(device)\n",
    "\n",
    "        # Predict action probabilities using the model\n",
    "        predicted_batch = self.model(state_batch)  # Probability distribution of actions\n",
    "        prob_batch = predicted_batch.gather(dim=1, index=action_batch.long().view(-1,1)).squeeze()\n",
    "        \n",
    "        # Loss calculation using the standardized returns (baseline)\n",
    "        loss = -torch.sum(torch.log(prob_batch) * (batch_Gvals))\n",
    "\n",
    "        # Optimize the model\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=10)\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # get loss\n",
    "        loss = loss.item()\n",
    "        losses.append(loss)\n",
    "\n",
    "        if verbose:\n",
    "            if t % 100 == 0 and t > 0:\n",
    "                print(f'Trajectory {t}\\tAverage Score: {np.mean(score[-100:-1]):.2f}')\n",
    "        self.env.close()\n",
    "\n",
    "        return score, losses\n",
    "        \n",
    "    # Training function\n",
    "    def train(self, verbose = True):\n",
    "        score = []\n",
    "        losses = []\n",
    "        for t in tqdm(range(self.max_trjectories)):\n",
    "            score, losses = self.train_episode(score, losses, t, self.horizon, verbose = verbose)\n",
    "\n",
    "        self.plot_loss(losses)\n",
    "\n",
    "        # save model \n",
    "        torch.save(self.model.state_dict(), f'rlmodel_{self.lr}_{self.max_trjectories}_{self.horizon}.pth')\n",
    "        return score\n",
    "    \n",
    "    # function to test the agent\n",
    "    def watch_agent(self, model_path = None, T = 500, episodes = 100, device = 'cpu'):\n",
    "        \n",
    "        # load the model if a path is provided\n",
    "        if model_path:\n",
    "            self.model.load_state_dict(torch.load(model_path, weights_only=True, map_location=device))\n",
    "            self.model.eval()\n",
    "\n",
    "        # store the scores and images of the episodes to make a gif\n",
    "        score = []\n",
    "        ep_imgs = []\n",
    "\n",
    "        # run n episodes, store the images and the scores\n",
    "        for _ in tqdm(range(episodes)):\n",
    "            current_state, _ = self.env.reset()\n",
    "            images = []\n",
    "            transitions = []\n",
    "            for _ in range(T):\n",
    "                current_state, done, transitions, img = self.step(transitions, current_state, render = True)\n",
    "                images.append(Image.fromarray(img))\n",
    "                if done:\n",
    "                    break           \n",
    "            rewards = np.array([r for (s, a, r) in transitions])\n",
    "            score.append(np.sum(rewards))\n",
    "            ep_imgs.append(images)\n",
    "\n",
    "        video_name = 'video.gif'\n",
    "        # save a gif of the best episode to visualize the agent\n",
    "        if video_name in os.listdir():\n",
    "            video_name = f'video_{self.max_trjectories}_{self.horizon}_{datetime.datetime.now()}.gif'\n",
    "        \n",
    "        ep_imgs[np.argmax(np.array(score))][0].save(f\"videos/{video_name}\", save_all=True, append_images=images[1:], duration=60, loop=0)\n",
    "        \n",
    "        # plot the scores\n",
    "        self.visualise(score, show_avg= False, train=False, name = 'reward_plot')\n",
    "\n",
    "        # close Env\n",
    "        self.env.close()\n",
    "        \n",
    "    # visualisation function\n",
    "    def visualise(self, score, show_avg=True, train=True, name = 'reward_plot', folder = 'rewards'):\n",
    "        score = np.array(score)\n",
    "\n",
    "        plt.figure(figsize=(15, 7))\n",
    "        plt.ylabel(\"Trajectory duration\", fontsize=12)\n",
    "        plt.xlabel(\"Training iterations\", fontsize=12)\n",
    "        \n",
    "        # Plot the score\n",
    "        plt.plot(score, color='gray', linewidth=1, label='Score')\n",
    "        \n",
    "        # Plot the moving average if enabled\n",
    "        if show_avg:\n",
    "            N = 100  # Window size\n",
    "            avg_score = np.convolve(score, np.ones(N) / N, mode='valid')\n",
    "            plt.plot(avg_score, color='blue', linewidth=3, label='Moving Average (window=50)')\n",
    "        \n",
    "        # Scatter plot for individual points\n",
    "        plt.scatter(np.arange(score.shape[0]), score, color='green', linewidth=0.3)\n",
    "        \n",
    "        # Add a legend\n",
    "        plt.legend(fontsize=12)\n",
    "        \n",
    "        if train:\n",
    "            if f'{name}_{self.lr}_{self.max_trjectories}_{self.horizon}.png' in os.listdir(folder):\n",
    "                plt.savefig(f'{folder}/{name}_{self.lr}_{self.max_trjectories}_{self.horizon}_{datetime.datetime.now()}.png')\n",
    "            else:\n",
    "                plt.savefig(f'{folder}/{name}_{self.lr}_{self.max_trjectories}_{self.horizon}.png')\n",
    "        \n",
    "        else:\n",
    "            name = f'test_{name}'\n",
    "            if f'{name}.png' in os.listdir(folder):\n",
    "                plt.savefig(f'{folder}/{name}_{datetime.datetime.now()}.png')\n",
    "            else:\n",
    "                plt.savefig(f'{folder}/{name}.png')\n",
    "    \n",
    "    def plot_loss(self, losses):\n",
    "        plt.figure(figsize=(15, 7))\n",
    "        plt.ylabel(\"Loss\", fontsize=12)\n",
    "        plt.xlabel(\"Training iterations\", fontsize=12)\n",
    "        plt.plot(losses, color='gray', linewidth=1, label='Loss')\n",
    "        # save the plot\n",
    "        if f'loss_plot_skip4_{self.lr}_{self.max_trjectories}_{self.horizon}.png' in os.listdir():\n",
    "            plt.savefig(f'loss_plot_skip4_{self.lr}_{self.max_trjectories}_{self.horizon}_{datetime.datetime.now()}.png')\n",
    "        else:\n",
    "            plt.savefig(f'loss_plot_skip4_{self.lr}_{self.max_trjectories}_{self.horizon}.png')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:23<00:00,  2.37s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "agent = RLAgent(env, lr = 1e-5, gamma = 0.995, max_trjectories = 100, horizon = 50000, device = device)\n",
    "agent.watch_agent(model_path = 'models/rlmodel_1e-05_500_10000_2.pth', T = 1000, episodes = 10, device = 'cpu')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paradigms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
